# clear-up the environment
rm(list = ls())
# chunk options
knitr::opts_chunk$set(
message = FALSE,
warning = FALSE,
fig.align = "center",
comment = "#>"
)
options(scipen = 9999)
bank <- read.csv("bank-full.csv")
head(bank)
bank <- read.csv("bank-full.csv", sep = ";")
head(bank)
glimpse(bank)
# untuk persiapan data
library(dplyr)
# untuk text processing
library(tm)
library(SnowballC)
library(inspectdf)
# untuk keperluan machine learning
library(e1071)
library(caret)
library(ROCR)
library(rsample)
library(partykit)
library(randomForest)
glimpse(bank)
bank <- read.csv("bank-full.csv", sep = ";", stringsAsFactors = T)
head(bank)
glimpse(bank)
summary(bank)
RNGkind(sample.kind = "Rounding")
set.seed(100)
split_bank <- sample(nrow(bank), nrow(bank)*0.80)
data_train <- bank[split_loan, ]
RNGkind(sample.kind = "Rounding")
set.seed(100)
split_bank <- sample(nrow(bank), nrow(bank)*0.80)
data_train <- bank[split_bank, ]
data_test <- bank[-split_bank, ]
prop.table(table(data_train$default))
library(caret)
set.seed(100)
data_train_down <- downSample(
x = data_train %>% select(-y),
y = data_train$y,
yname = "y"
)
head(data_train_down)
prop.table(table(data_train$y))
prop.table(table(data_train_down$y))
model_naive <- naiveBayes(
formula = y ~ .,
data = data_train_down,
laplace = 1
)
model_naive
# your code here
pred_naive <- predict(
object = model_naive,
newdata = data_test,
type = "class"
)
confusionMatrix(
data = pred_naive,
reference = data_test$y,
positive = "yes",
mode = "everything"
)
set.seed(100)
model_dt <- ctree(formula = default ~ .,
data = data_train_down,
control = ctree_control(mincriterion = 0.90))
# your code here
plot(model_dt, type = "simple")
set.seed(100)
model_dt <- ctree(formula = y ~ .,
data = data_train_down,
control = ctree_control(mincriterion = 0.90))
# your code here
plot(model_dt, type = "simple")
# your code here
plot(model_dt, type = "simple")
# your code here
plot(model_dt, type = "simple")
# your code here
plot(model_dt, type = "simple")
# your code here
plot(model_dt, type = "simple")
set.seed(100)
model_dt <- ctree(formula = y ~ .,
data = data_train_down,
control = ctree_control(mincriterion = 0.95))
# your code here
plot(model_dt, type = "simple")
set.seed(100)
model_dt <- ctree(formula = y ~ .,
data = data_train_down,
control = ctree_control(mincriterion = 0.97))
# your code here
plot(model_dt, type = "simple")
set.seed(100)
model_dt <- ctree(formula = y ~ .,
data = data_train_down,
control = ctree_control(mincriterion = 0.90))
# your code here
plot(model_dt, type = "simple")
set.seed(100)
model_dt <- ctree(formula = y ~ .,
data = data_train_down,
control = ctree_control(mincriterion = 0.80))
# your code here
plot(model_dt, type = "simple")
set.seed(100)
model_dt <- ctree(formula = y ~ .,
data = data_train_down,
control = ctree_control(mincriterion = 0.99))
# your code here
plot(model_dt, type = "simple")
set.seed(100)
model_dt <- ctree(formula = y ~ .,
data = data_train_down,
control = ctree_control(mincriterion = 0.98))
# your code here
plot(model_dt, type = "simple")
set.seed(100)
model_dt <- ctree(formula = y ~ .,
data = data_train_down,
control = ctree_control(mincriterion = 0.95))
# your code here
plot(model_dt, type = "simple")
# your code here
pred_dt <- predict(model_dt,
data_test,
type = "response")
# your code here
confusionMatrix(
data = pred_dt,
reference = data_test$y,
positive = "yes",
mode = "everything"
)
set.seed(100)
# # definisikan training control untuk repeated k-fold cross validation
train_ctrl <- trainControl(method = "repeatedcv",
number = 5, # seberapa banyak kita ingin membagi data
repeats = 3)
# # training model random forest dengan train()
bank_forest <- train(bank ~ .,
data = data_train_down,
method = "rf", # pilih metode random forest
trControl = train_ctrl)
set.seed(100)
# # definisikan training control untuk repeated k-fold cross validation
train_ctrl <- trainControl(method = "repeatedcv",
number = 5, # seberapa banyak kita ingin membagi data
repeats = 3)
# # training model random forest dengan train()
bank_forest <- train(y ~ .,
data = data_train_down,
method = "rf", # pilih metode random forest
trControl = train_ctrl)
# menyimpan model ke format RDS
saveRDS(bank_forest, "model_rf.RDS")
#library(randomForest)
# your code here
bank_forest$finalModel
# your code here
varImp(bank_forest) %>% plot()
# your code here
pred_rf <- predict(
bank_forest,
data_test,
type = "raw"
)
# your code here
confusionMatrix(
data = pred_rf,
reference = data_test$y,
positive = "yes",
mode = "everything"
)
# your code here
prob_test <- predict(bank_forest,
data_test,
type = "prob")
prob_test[,"yes"]
pred_roc <- prediction(predictions = prob_test[,"yes"],
labels = data_test$default)
# your code here
perf <- performance(pred_roc,
"tpr",
"fpr")
# your code here
plot(perf)
abline(0,1 , lty = 2)
auc <- performance(pred_roc, "auc")
auc@y.values[[1]]
pred_roc <- prediction(predictions = prob_test[,"yes"],
labels = data_test$y)
pred_roc <- prediction(predictions = prob_test[,"yes"],
labels = data_test$y)
# your code here
perf <- performance(pred_roc,
"tpr",
"fpr")
# your code here
plot(perf)
abline(0,1 , lty = 2)
auc <- performance(pred_roc, "auc")
auc@y.values[[1]]
